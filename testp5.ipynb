{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eb02bc5-220c-4d49-912b-e04a22e58429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "    # takes argument of a url on the course website and returns a string\n",
    "    # containing all of the python code in the lecture formatted in a way\n",
    "    # to save it as a python file and run without syntax issues\n",
    "def scrape_code(url: str) -> str:\n",
    "    req_obj = requests.get(url)\n",
    "    bs = BeautifulSoup(req_obj.text)\n",
    "    blocks = bs.find_all('code', class_ = 'sourceCode python')\n",
    "    list = []\n",
    "    for code in blocks:\n",
    "        line = code.text.strip().split('\\n')\n",
    "        list += line\n",
    "    string = '\\n'.join(list)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b07b1939-1662-4278-8c24-fe1c3d62b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_range = range(1000000)\n",
      "raw_list = list(raw_range)\n",
      "%timeit raw_list_x_2 = [x*2 for x in raw_list]\n",
      "new_list = []\n",
      "%timeit for x in raw_list: new_list.append(x*2)\n",
      "import numpy as np\n",
      "\n",
      "raw_array = np.arange(1000000)\n",
      "%timeit raw_array_x_2 = 2 * raw_array\n",
      "def inner_product_slow(x_1: list, x_2: list) -> float:\n",
      "    \"\"\"\n",
      "    Compute the inner product of two lists\n",
      "    \"\"\"\n",
      "\n",
      "    inner_prod = 0\n",
      "    for i in range(len(x_1)):\n",
      "        inner_prod += x_1[i] * x_2[i]\n",
      "    return inner_prod\n",
      "\n",
      "x_1 = list(range(100))\n",
      "x_2 = list(range(100, 200))\n",
      "%timeit inner_product_slow(x_1,x_2)\n",
      "x_1_arr = np.arange(100)\n",
      "x_2_arr = np.arange(100,200)\n",
      "%timeit np.inner(x_1_arr, x_2_arr)\n",
      "np.inner(x_1_arr,x_2_arr) == inner_product_slow(x_1,x_2)\n",
      "%timeit np.prod(np.arange(1,11))\n",
      "%%time\n",
      "\n",
      "out = 1\n",
      "for i in range(1,11):\n",
      "    out *= i\n",
      "A = np.arange(10).reshape((5,2))\n",
      "B = np.arange(10, 20).reshape((2,5))\n",
      "\n",
      "print(f'Matrix A:\\n {A}')\n",
      "print(f'Matrix B:\\n {B}')\n",
      "print(f'Product:\\n {A @ B}')\n",
      "len_one_arr = np.ones(10)\n",
      "len_one_arr.shape\n",
      "len_two_arr = len_one_arr.reshape((-1,1))\n",
      "len_two_arr.shape\n",
      "len_three_arr = len_one_arr.reshape((-1,2,1))\n",
      "len_three_arr.shape\n",
      "len_one_arr.reshape((3,-1))\n",
      "my_arr = np.arange(20).reshape((4,5))\n",
      "my_arr\n",
      "my_arr[0,:]\n",
      "my_arr[:,0]\n",
      "my_arr[:3,:2]\n",
      "5. * my_arr\n",
      "1. / my_arr\n",
      "my_arr * my_arr\n",
      "my_arr > 10.\n",
      "new_arr = np.array([4,1,0,6,6,2,6,9,6,7]).reshape((5,2))\n",
      "new_arr\n",
      "cond = np.sum(new_arr, axis = 1) > 10\n",
      "cond\n",
      "print(new_arr[cond])\n",
      "print(new_arr[~cond])\n",
      "def my_abs(arr: np.array) -> np.array:\n",
      "    \"\"\"Compute absolute value of an array\"\"\"\n",
      "\n",
      "    neg_elements = arr < 0\n",
      "    arr[neg_elements] = arr[neg_elements] * -1\n",
      "    return arr\n",
      "\n",
      "my_abs(np.arange(-3,3))\n",
      "np.arange(-3,3) * np.sign(np.arange(-3,3))\n",
      "np.exp(my_arr)\n",
      "np.sqrt(my_arr)\n",
      "my_arr\n",
      "np.sum(my_arr)\n",
      "np.sum(my_arr, axis = 0)\n",
      "np.sum(my_arr, axis = 1)\n",
      "a = new_arr[:,0]\n",
      "b = new_arr[:,1]\n",
      "print(a,b)\n",
      "np.maximum(a,b)\n",
      "np.max(new_arr, axis = 1)\n",
      "vec = np.arange(5).reshape((-1,5))\n",
      "mat = np.ones(15).reshape((-1,5))\n",
      "print(f'vec shape: {vec.shape}, mat shape: {mat.shape}')\n",
      "(mat / vec).shape\n",
      "(vec / mat).shape\n",
      "print(vec)\n",
      "print(mat)\n",
      "print(mat / vec)\n",
      "print(vec / mat)\n",
      "mat / np.ones(3)\n",
      "np.ones((5,2,1)) / np.ones((4,1,1))\n",
      "draws = np.random.multivariate_normal(\n",
      "    mean = np.arange(6,9),\n",
      "    cov = np.diag(np.arange(1,4)),\n",
      "    size = 1000\n",
      ")\n",
      "demeaned_draws = draws - np.mean(draws, axis = 0)\n",
      "demeaned_draws.T @ demeaned_draws / 1000\n",
      "def standardize(arr: np.array) -> np.array: \n",
      "    \"\"\"\n",
      "    Standardize the features in `arr`\n",
      "    \"\"\"\n",
      "\n",
      "    mu_j = np.mean(arr, axis = 0)\n",
      "    sigma_j = np.std(arr, axis = 0)\n",
      "\n",
      "    return (arr - mu_j) / sigma_j\n",
      "\n",
      "standardize(new_arr)\n",
      "draws = np.random.standard_normal(100000)\n",
      "print(np.mean(draws), np.std(draws))\n",
      "rng = np.random.default_rng(seed=481) # rng = random number generator\n",
      "rng_draws = rng.standard_normal(100000)\n",
      "print(np.mean(rng_draws), np.std(rng_draws))\n",
      "%%time\n",
      "rng = np.random.default_rng(seed=481)\n",
      "\n",
      "sample_means = []\n",
      "for i in range(1000):\n",
      "    sample_means.append(np.mean(rng.standard_normal(size=1000)))\n",
      "\n",
      "print(np.mean(sample_means), np.std(sample_means))\n",
      "%%time\n",
      "rng = np.random.default_rng(seed=481)\n",
      "\n",
      "random_draws = rng.standard_normal(size=1000*1000).reshape((1000,1000))\n",
      "sample_means = np.mean(random_draws, axis = 0)\n",
      "\n",
      "print(np.mean(sample_means), np.std(sample_means))\n",
      "print(0, np.sqrt(1./1000))\n",
      "X = np.array(\n",
      "    [\n",
      "        [2,1200,3.2,0],\n",
      "        [1,1400,3.8,1],\n",
      "        [19,900,2.5,0],\n",
      "        [10,1400,3.8,1],\n",
      "        [5,1000,3.0,0],\n",
      "        [4,1100,3.9,0]\n",
      "    ]\n",
      ")\n",
      "y = np.array([60000, 90000, 30000, 200000, 150000, 30000]).reshape(-1,1)\n",
      "\n",
      "print(X.shape, y.shape)\n",
      "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
      "beta_hat\n",
      "X_int = np.concatenate(\n",
      "    [\n",
      "        np.ones(X.shape[0]).reshape(-1,1),\n",
      "        X,\n",
      "    ],\n",
      "    axis = 1\n",
      ")\n",
      "X_int\n",
      "np.concatenate(\n",
      "    [\n",
      "        np.ones(X.shape[0]).reshape(-1,1),\n",
      "        X,\n",
      "    ]\n",
      ")\n",
      "np.c_[np.ones(X.shape[0]).reshape(-1,1), X]\n",
      "np.hstack((np.ones(X.shape[0]).reshape(-1,1), X))\n",
      "beta_hat_int = np.linalg.inv(X_int.T @ X_int) @ X_int.T @ y\n",
      "beta_hat_int\n",
      "from sklearn.linear_model import LinearRegression\n",
      "reg_model = LinearRegression(fit_intercept=False).fit(X_int, y)\n",
      "reg_model.coef_\n",
      "np.allclose(beta_hat_int.flatten(), reg_model.coef_)\n",
      "import matplotlib.pyplot as plt\n",
      "k = 100\n",
      "p = .35\n",
      "n = 10000\n",
      "x_i = np.random.binomial(n=k, p=p, size=n)\n",
      "plt.hist(x_i)\n",
      "plt.show()\n",
      "p_mle = (1./n) * np.sum(x_i/k)\n",
      "p_mle\n",
      "def neg_ll(theta: float, data: np.array, k: int) -> float:\n",
      "    \"\"\"\n",
      "    Compute the negative (why?) log-likelihood for a \n",
      "    binomial distribution given data and a specific parameter (theta). \n",
      "    The factorial term is omitted (why?)\n",
      "    \"\"\"\n",
      "\n",
      "    p_successes = data * np.log(theta)\n",
      "    p_failures = (k-data) * np.log(1-theta)\n",
      "\n",
      "    return -np.sum(p_successes + p_failures)\n",
      "\n",
      "print(f'Log-Likelihood when we\\'re far away: {-neg_ll(.8, x_i, k)}')\n",
      "print(f'Log-Likelihood when we\\'re close: {-neg_ll(.3, x_i, k)}')\n",
      "import scipy as sp\n",
      "\n",
      "sp.optimize.minimize(\n",
      "    fun=neg_ll, # the objective function\n",
      "    x0=.25, # starting guess\n",
      "    args=(x_i, k), # additional parameters passed to neg_ll\n",
      "    bounds = ((0,1),), # bounds for the optimization\n",
      "    method = 'Nelder-Mead' # optionally pick an algorithm\n",
      ")\n",
      "sp.optimize.minimize(\n",
      "    fun=neg_ll, # the objective function\n",
      "    x0=.25, # starting guess\n",
      "    args=(x_i, k), # additional parameters passed to neg_ll\n",
      "    bounds = ((0,1),) # bounds for the optimization\n",
      ")\n",
      "%%time\n",
      "rng = np.random.default_rng(seed = 481)\n",
      "\n",
      "chain = []\n",
      "x = 0\n",
      "\n",
      "for i in range(1000):\n",
      "    x += rng.standard_normal()\n",
      "    chain.append(x)\n",
      "%%time\n",
      "rng = np.random.default_rng(seed = 481)\n",
      "\n",
      "chain = np.cumsum(rng.standard_normal(size = 1000))\n",
      "plt.plot(chain)\n",
      "def met_hast(n_iterations: int) -> list:\n",
      "    \"\"\"\n",
      "    Run Metropolis-Hastings algorithm for our binomial example.\n",
      "    \"\"\"\n",
      "    post_draws = []\n",
      "    theta_old = .5\n",
      "    for i in range(n_iterations):\n",
      "        theta_new = theta_old + np.random.normal(loc = 0, scale = .05)\n",
      "        ll_old = -neg_ll(theta_old, x_i, k)\n",
      "        ll_new = -neg_ll(theta_new, x_i, k)\n",
      "        acceptance_rate = np.exp(ll_new-ll_old)\n",
      "        if np.random.uniform() < acceptance_rate:\n",
      "            post_draws.append(theta_new)\n",
      "            theta_old = theta_new\n",
      "        else:\n",
      "            post_draws.append(theta_old)\n",
      "    \n",
      "    return post_draws\n",
      "simulation_draws = met_hast(10000)\n",
      "print(f'Mean of posterior draws: {round(np.mean(simulation_draws),4)}')\n",
      "plt.plot(range(10000), simulation_draws)\n",
      "print(f'Mean of posterior draws: {round(np.mean(simulation_draws[1000:]),4)}')\n",
      "plt.plot(range(1000,10000), simulation_draws[1000:])\n",
      "plt.hist(simulation_draws[1000:])\n",
      "plt.show()\n"
     ]
    }
   ],
   "source": [
    "test = \"https://lukashager.netlify.app/econ-481/01_intro_to_python#/strings\"\n",
    "test2 = \"https://lukashager.netlify.app/econ-481/00_intro_to_481\"\n",
    "test3 = \"https://lukashager.netlify.app/econ-481/02_numerical_computing_in_python\"\n",
    "print(scrape_code(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "217867b1-0790-4012-86de-665ce2812100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_code(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe15230-eeb3-4a17-b0d8-3386b27abe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
